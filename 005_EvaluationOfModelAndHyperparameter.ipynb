{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가와 하이퍼파라미터\n",
    "\n",
    "\"\"\"\n",
    "K-Fold Cross Validation  K겹 교차 검증\n",
    "\n",
    "Training set으로 모델을 학습시키고 test set로 모델을 평가할 경우,\n",
    "\n",
    "운에 따라 test set에서만 성능이 좋거나, 반대로 test set에서만 성능이 나쁠 수 있다.\n",
    "\n",
    "이 불균형을 k겹 교차 검증을 통하여 해소할 수 있다.\n",
    "\n",
    "<절차>\n",
    "데이터를 k개의 같은 사이즈로 나눈다.\n",
    "k = 5, 데이터가 1000개일 경우,\n",
    "데이터를 200개씩 5개의 set으로 나눈다.\n",
    "\n",
    "[data 200] ---> test set\n",
    "[data 200] ---> 나머지: training set\n",
    "[data 200]\n",
    "[data 200]\n",
    "[data 200]\n",
    "위와 같이 하나의 데이터 셋을 test set으로, 나머지를 training set으로 하여 성능을 평가한다.\n",
    "이 것을 각 다섯 데이터마다 한번씩 반복한 후 각 성능의 평균을 본 모델의 성능으로 보는 것이다.\n",
    "\n",
    "일반적으로 k에 사용하는 숫자는 5이다.\n",
    "데이터가 많을 경우, 우연히 test set에서만 성능이 낮을 확률이 적기 때문에, 그 경우에는 낮은 k를 사용해도 된다.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biological-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn으로 k-fold cross validation 해보기\n",
    "\n",
    "# 붓꽃의 속성으로 붓꽃을 맞추는 모델. train test split을 진행하지 않고 k-fold cross validation을 사용하여 학습.\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invisible-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "overhead-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "y = pd.DataFrame(iris_data.target, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stock-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brave-party",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "\n",
      "평균\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보통은 여기서 train test split으로 training set 과 test set 을 분리한다.\n",
    "\n",
    "print(cross_val_score(logistic_model, X, y.values.ravel(), cv=5))\n",
    "# 파라미터에 모델과 X, y를 모두 넣어 k겹 교차 검증을 통해 로지스틱 회귀 학습을 시킨다.\n",
    "\n",
    "print('')\n",
    "# 옵셔널 파라미터 cv는 k값이며, sklearn 0.22ver 이후로 기본값은 5이다.\n",
    "\n",
    "# 각 성능을 평균내기\n",
    "print('평균')\n",
    "np.average(cross_val_score(logistic_model, X, y.values.ravel(), cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습과제\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "GENDER_FILE_PATH = './datasets/gender.csv'\n",
    "\n",
    "# 성별에 관한 데이터 셋을 가지고 온다\n",
    "gender_df = pd.read_csv(GENDER_FILE_PATH)\n",
    "\n",
    "X = pd.get_dummies(gender_df.drop(['Gender'], axis=1)) # 입력 변수를 one-hot encode한다 \n",
    "# (주류에 와인, 맥주가 있다면 주류_와인, 주류_맥주 컬럼 생성하여 값 (0, 1)로 해당 여부 판별\n",
    "y = gender_df[['Gender']].values.ravel()\n",
    "\n",
    "# 여기에 코드를 쓰세요\n",
    "logistic_model = LogisticRegression(solver='saga', max_iter=2000)\n",
    "k_fold_score = np.average(cross_val_score(logistic_model, X, y, cv=5))\n",
    "\n",
    "# 체점용 코드\n",
    "k_fold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "diagnostic-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n위와 같이 Lasso 회귀 모델을 생성할 때 alpha와 max_iter와 같은 옵셔널 파라미터.\\n즉 머신 러닝 모델을 학습시키기 전에 '사람이 미리 정해줘야 되는 변수'들이 '하이퍼파라미터'이다.\\nsklearn을 기준으로는 모델을 만들 때 옵셔널 파라미터로 정해주는 변수이다.\\n\\n이 때, 좋은 hyperparameter를 찾기 좋은 방법으로 Grid Search가 있다.\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter 하이퍼파라미터\n",
    "\n",
    "# model = Lasso(alpha=0.001, max_iter=1000)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "위와 같이 Lasso 회귀 모델을 생성할 때 alpha와 max_iter와 같은 옵셔널 파라미터.\n",
    "즉 머신 러닝 모델을 학습시키기 전에 '사람이 미리 정해줘야 되는 변수'들이 '하이퍼파라미터'이다.\n",
    "sklearn을 기준으로는 모델을 만들 때 옵셔널 파라미터로 정해주는 변수이다.\n",
    "\n",
    "이 때, 좋은 hyperparameter를 찾는 유용한 방법으로 Grid Search가 있다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search  그리드 서치\n",
    "\n",
    "\"\"\"\n",
    "정해줘야 하는 각 hyperparameter에 넣어보고 싶은 후보 값을 몇 개씩 정한다.\n",
    "alpha와 iter_max 두 가지만 찾는다고 하면 아래와 같은 표를 만들 수 있다.\n",
    "표의 행: max_iter에 넣어볼 후보 값[1000, 2000, 3000]\n",
    "표의 열: alpha에 넣어볼 후보 값[0.1, 1, 10]\n",
    "\n",
    "[0, 0] alpha=0.1, max_iter=1000일 때 성능\n",
    "[0, 1] alpha=1, max_iter=1000일 때 성능 \n",
    "[0, 2] alpha=10, max_iter=1000일 때 성능\n",
    "[1, 0] alpha=0.1, max_iter=2000일 때 성능\n",
    "[1, 1] alpha=1, max_iter=2000일 때 성능\n",
    "[1, 2] alpha=10, max_iter=2000일 때 성능\n",
    "[2, 0] alpha=0.1, max_iter=3000일 때 성능\n",
    "[2, 1] alpha=1, max_iter=3000일 때 성능\n",
    "[2, 2] alpha=10, max_iter=3000일 때 성능\n",
    "\n",
    "격자 모양의 표를 그려 해당 성능 중 가장 좋은 부분의 hyperparameter를 찾는 방법이기 때문에 grid search라고 한다.\n",
    "\n",
    "시각적으로 보기 어렵더라도, \n",
    "두 개를 초과하는 hyperparameter의 경우에도 그리드 서치 방법을 사용하여 성능이 가장 좋게 나오는 하이퍼파라미터를 찾을 수 있을 것이다.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
