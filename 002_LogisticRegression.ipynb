{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hungarian-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n로지스틱 회귀 Logistic Regression\\n\\n분류 문제\\n\\nML은 지도학습, 비지도학습으로 나뉜다.\\n여기서 지도학습은 회귀 문제와 분류 문제로 나뉜다.\\n\\n예를들어 스팸 메일의 구분, 기사의 성격(스포츠, 사회, 연예 등) 구분 등은 분류 문제이다.\\n이 경우 [0, 1] 또는 [0, 1, 2] 등으로 각 값을 구분하여 분류할 수 있다.\\n\\n분류는 사실 선형회귀로도 쉽게 가능하다.\\n그러나 선형회귀는 예외적인 데이터에 너무 민감하게 반응하므로,\\n[0, 1] 가 되는 기준이 갑작스럽게 크기 변동할 수 있다.\\n\\n이 경우 로지스틱 회귀로 분류 문제를 지도할 수 있다.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "로지스틱 회귀 Logistic Regression\n",
    "\n",
    "분류 문제\n",
    "\n",
    "ML은 지도학습, 비지도학습으로 나뉜다.\n",
    "여기서 다시 지도학습은 회귀 문제와 분류 문제로 나뉜다.\n",
    "\n",
    "예를들어 스팸 메일의 구분, 신문기사의 성격(스포츠, 사회, 연예 등) 구분 등은 분류 문제이다.\n",
    "이 경우 [0, 1] 또는 [0, 1, 2] 등으로 각 값을 구분하여 분류할 수 있다.\n",
    "\n",
    "분류는 사실 선형회귀로도 쉽게 가능하다.\n",
    "그러나 선형회귀는 예외적인 데이터에 너무 민감하게 반응하므로,\n",
    "예외적인 데이터에 의해 [0, 1] 가 되는 기준이 갑작스럽게 크게 변동할 수 있다.\n",
    "\n",
    "이 경우 선형 회귀 대신 로지스틱 회귀 모델로 분류 문제를 지도할 수 있다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "linear-encounter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n선형회귀는 데이터가 있다면, 그것에 가장 잘 맞는 일차 함수를 찾는 것이다.\\n\\n로지스틱 회귀는 일차함수가 아닌, 시그모이드Sigmoid 함수를 찾는다.\\n\\n\\nS(x) = 1 / (1 + e ** -x) , 여기서 e = 2.718 \\n\\n예시1) 목표변수 x에 무한대 대입\\nx = ∞\\n\\ne의 마이너스 무한대 제곱은 0이다. 따라서, \\n\\nS(x) = 1 / (1 + 0)  \\n\\n= 1\\n\\n\\n\\n\\n예시2) 목표변수 x에 마이너스 무한대 대입\\nx = -∞\\n\\ne 의 마이너스 마이너스 무한대 제곱은 무한대이다. 따라서,\\n\\nS(x) = 1 / 1 + ∞\\n\\n= 1 / ∞\\n\\n= 0\\n \\n\\n결과적으로 x가 작을 수록 시그모이드 함수의 결과 값은 0에 가까워지고,\\nx가 클 수록 결과 값은 1에 가까워진다.\\n즉 모든 결과 값은 0과 1의 사이이므로 더 유용한 분류가 가능하다.\\n또한 시그모이드 함수는 S자 형태로, 많이 동떨어진 데이터에도 큰 영향을 받지 않는다.\\n\\n\\nQ) 분류를 하기 위해 쓰이는데 왜 이름이 로지스틱 '회귀'일까?\\n\\nA) 시그모이드 함수의 결괏값도 결국 0과 1 사이의 연속적인 값이기 때문에 회귀이다.\\n  정확히는 함수의 결괏값이 0.5보다 큰지 작은지만 확인하여 '분류' 하는 것이다.\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "선형회귀는 데이터가 있다면, 그것에 가장 잘 맞는 일차 함수를 찾는 것이다.\n",
    "\n",
    "로지스틱 회귀는 일차함수가 아닌, 시그모이드Sigmoid 함수를 찾는다.\n",
    "\n",
    "\n",
    "S(x) = 1 / (1 + e ** -x) , 여기서 e = 2.718... (자연상수 = 자연로그의 밑)\n",
    "\n",
    "\n",
    "예시1) 목표변수 x에 무한대 대입\n",
    "x = ∞\n",
    "\n",
    "e의 마이너스 무한대 제곱은 0이다. 따라서, \n",
    "\n",
    "S(x) = 1 / (1 + 0)  \n",
    "\n",
    "= 1\n",
    "\n",
    "\n",
    "\n",
    "예시2) 목표변수 x에 마이너스 무한대 대입\n",
    "x = -∞\n",
    "\n",
    "e 의 마이너스 마이너스 무한대 제곱은 무한대이다. 따라서,\n",
    "\n",
    "S(x) = 1 / 1 + ∞\n",
    "\n",
    "= 1 / ∞\n",
    "\n",
    "= 0\n",
    " \n",
    "\n",
    "결과적으로 x가 작을 수록 시그모이드 함수의 결과 값은 0에 가까워지고,\n",
    "x가 클 수록 결과 값은 1에 가까워진다.\n",
    "즉 모든 결과 값은 0과 1 사이이므로 더 유용한 분류가 가능하다.\n",
    "또한 시그모이드 함수는 S자 형태로, 많이 동떨어진 데이터에도 큰 영향을 받지 않는다.\n",
    "\n",
    "\n",
    "Q) '분류'를 하기 위해 쓰이는데 왜 이름이 로지스틱 '회귀'일까?\n",
    "\n",
    "A) 시그모이드 함수의 결괏값도 결국 0과 1 사이의 연속적인 값이기 때문에 회귀이다.\n",
    "  정확히는 함수의 결괏값이 0.5보다 큰지 작은지만 확인하여 '분류' 하는 것이다.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "noticed-syndrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nΘ theta\\n\\n로지스틱 회귀 가설 함수\\n\\n선형회귀의 가설함수를 행렬연산(벡터)로 표현하면 아래와 같다.\\nhΘ(x) = Θ.T @ x (theta벡터의 전치행렬과 x벡터의 곱)\\n\\n로지스틱 회귀의 가설 함수를 위하여 선형 회귀 가설 함수는 g로 설정\\ngΘ(x) = Θ.T @ x\\n\\n로지스틱 회귀의 가설 함수는 아래와 같다.\\nhΘ(x) = 1 / (1 + e ** -g(x))\\n\\n위의 식에서 함수 g를 대입할 경우 아래와 같다.\\nhΘ(x) = 1 / (1 + e ** -Θ.T @ x)\\n\\n여기서 함수 g는 일차 함수이다.\\n일차 함수는 아웃풋이 매우 클 수도, 작을 수도 있다. (우상향 직선일수록 더더욱)\\n\\n로지스틱 회귀를 할 때에는 아웃풋이 항상 0과 1 사이에 떨어지도록 하고 싶기 때문에\\n아래와 같은 시그모이드 함수를 스는 것이다.\\nS(x) = 1 / (1 + e ** -x)\\n\\n나중에 위의 가설 함수에 목표변수 x 벡터를 대입한다고 가정했을 때,\\n0 ~ 1 사이의 값이 나올 것이고, 해당 값에 따라 목표 변수를 분류할 수 있다.\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Θ theta\n",
    "\n",
    "로지스틱 회귀 가설 함수\n",
    "\n",
    "선형회귀의 가설함수를 행렬연산(벡터)로 표현하면 아래와 같다.\n",
    "hΘ(x) = Θ.T @ x (theta벡터의 전치행렬과 x벡터의 곱)\n",
    "\n",
    "로지스틱 회귀의 가설 함수를 위하여 위의 선형 회귀 가설 함수는 g로 설정\n",
    "gΘ(x) = Θ.T @ x\n",
    "\n",
    "로지스틱 회귀의 가설 함수는 아래와 같다.\n",
    "hΘ(x) = 1 / (1 + e ** -g(x))\n",
    "\n",
    "위의 식에서 함수 g를 대입할 경우 아래와 같다.\n",
    "hΘ(x) = 1 / (1 + e ** -Θ.T @ x)\n",
    "\n",
    "여기서 함수 g는 일차 함수이다.\n",
    "일차 함수는 아웃풋이 매우 클 수도, 작을 수도 있다. (우상향 직선일수록 더더욱)\n",
    "\n",
    "로지스틱 회귀를 할 때에는 아웃풋이 항상 0과 1 사이에 떨어지도록 하고 싶기 때문에\n",
    "아래와 같은 시그모이드 함수를 쓰는 것이다.\n",
    "S(x) = 1 / (1 + e ** -x)\n",
    "\n",
    "나중에 위의 가설 함수에 목표변수 x 벡터를 대입한다고 가정했을 때,\n",
    "0 ~ 1 사이의 값이 나올 것이고, 해당 값에 따라 목표 변수를 분류할 수 있다.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "overhead-request",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n로지스틱 회귀에서 하려는 것\\n\\nhΘ(x) = 1 / (1 + e ** -Θ.T @ x)\\n\\n선형 회귀와 똑같이 theta0, theta1의 값을 바꿔가며,\\n가지고 있는 train set에 가장 잘 맞는 sigmoid 모양의 곡선을 찾아내는 것이다.\\n\\n\\n\\n변수가 여러개일 때\\n\\n입력 변수가 여러개면 시각화하기 어려우나, 개념 자체는 기본이나 심화 모두 동일하다.\\n(최적의 theta 값을 찾아가는 것)\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "로지스틱 회귀에서 하려는 것\n",
    "\n",
    "hΘ(x) = 1 / (1 + e ** -Θ.T @ x)\n",
    "\n",
    "선형 회귀와 똑같이 theta0, theta1의 값을 바꿔가며,\n",
    "가지고 있는 train set에 가장 잘 맞는 sigmoid 모양의 곡선을 찾아내는 것이다.\n",
    "\n",
    "\n",
    "\n",
    "변수가 여러개일 때\n",
    "\n",
    "입력 변수가 여러개면 시각화하기 어려우나, 개념 자체는 기본이나 심화 모두 동일하다.\n",
    "(최적의 theta 값을 찾아가는 것)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "transsexual-terror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n결정 경계 \\n\\nDecision Boundary : \\n속성이 하나 또는 둘일 때, 분류를 한 후 그 분류를 구별하는 경계선\\n로지스틱 회귀에서만 사용하는 용어는 아니며, 분류를 하는 모든 문제에 적용 가능.\\n\\n0.5로 시험의 합격, 불합격이 나뉘어진다고 가정했을 때,\\n\\nhΘ(x) = 1 / (1 + e ** -Θ.T @ x) = 0.5 을 통하여,\\n\\nx1과 x2의 관계식을 구할 수 있다.\\n(예를들어 x2 = -2x1 + 100 등)\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "결정 경계 \n",
    "\n",
    "Decision Boundary : \n",
    "속성이 하나 또는 둘일 때, 분류를 한 후 그 분류를 구별하는 경계선\n",
    "로지스틱 회귀에서만 사용하는 용어는 아니며, 분류를 하는 모든 문제에 적용 가능.\n",
    "\n",
    "0.5로 시험의 합격, 불합격이 나뉘어진다고 가정했을 때,\n",
    "\n",
    "hΘ(x) = 1 / (1 + e ** -Θ.T @ x) = 0.5 을 통하여,\n",
    "\n",
    "x1과 x2의 관계식을 구할 수 있다.\n",
    "(예를들어 x2 = -2x1 + 100 등)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "connected-system",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n로그 손실 (log-loss, cross enigma)\\n\\n공부량에 따른 시험 합격 여부의 경우, 목표 변수가 두 가지밖에 없다.\\n합격(1), 불합격(0). 즉 해당 목표 변수에 알맞는 로그 손실 함수가 별도 존재한다.\\ny = 1, -log(hΘ(x))\\ny = 0, -log(1 - hΘ(x))\\n\\n위의 식은 아래의 식과 같이 한 줄로 만들 수 있는데,\\ny 값을 1 또는 0 으로 대입하여 계산하면 위의 별도 함수와 동일한 결괏값이 나온다.\\nlogloss(hΘ(x), y) = -y log(hΘ(x)) - (1 - y)log(1 - hΘ(x))\\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "로그 손실 (log-loss, cross enigma)\n",
    "\n",
    "공부량에 따른 시험 합격 여부의 경우, 목표 변수가 두 가지밖에 없다.\n",
    "합격(1), 불합격(0). 즉 해당 목표 변수에 알맞는 로그 손실 함수가 별도 존재한다.\n",
    "y = 1, -log(hΘ(x))\n",
    "y = 0, -log(1 - hΘ(x))\n",
    "\n",
    "위의 식은 아래의 식과 같이 한 줄로 만들 수 있는데,\n",
    "y 값을 1 또는 0 으로 대입하여 계산하면 위의 별도 함수와 동일한 결괏값이 나온다.\n",
    "logloss(hΘ(x), y) = -y log(hΘ(x)) - (1 - y)log(1 - hΘ(x))\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "overall-translation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n로지스틱 회귀 경사 하강법\\n\\n1. 손실함수를 theta에 대하여 편미분\\n2, 편미분 결과에 학습률 알파 곱\\n3. 곱한 결괏값을 기존 theta에서 빼서 업데이트\\n\\n선형회귀와의 차이점은 손실함수 J가 다르다는 것이다.\\n\\n그런데, 로지스틱 회귀의 손실 함수 J를 theta에 대하여 편미분하면\\n선형 회귀의 손실 함수 J를 편미분한 결괏값과 동일하다.\\n\\n이제 여기서 유일하게 다른 건 가설함수 h이다.\\n가설 함수)\\n선형 회귀 : 일차 함수\\n로지스틱 회귀 : 시그모이드 함수\\n\\n즉 아래 값의 h에 시그모이드 함수를 대입하여 각 theta 값을 업데이트 하면 된다.\\nθj =θj −α / 1 m i=1∑m (hθ(x(i))−y(i)) * xj(i)\\n\\n손실함수 J를 편미분한 값에서 h에 시그모이드 함수를 대입하고,\\n입력변수 m을 모두 대입하여 계산 후, 그 합계를 낸 다음,\\nm으로 다시 나누어 평균을 낸 값에 알파값을 곱한 결괏값을 theta에서 빼서 업데이트.\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "로지스틱 회귀 경사 하강법\n",
    "\n",
    "1. 손실함수를 theta에 대하여 편미분 (선형 회귀의 결괏값과 동일)\n",
    "2, 편미분 결과에 학습률 알파 곱\n",
    "3. 곱한 결괏값을 기존 theta에서 빼서 업데이트\n",
    "\n",
    "선형회귀와의 차이점은 손실함수 J의 모양이 선형 회귀의 J와 다르다는 것이다.\n",
    "\n",
    "그런데, 로지스틱 회귀의 손실 함수 J를 theta에 대하여 편미분하면\n",
    "선형 회귀의 손실 함수 J를 편미분한 결괏값과 동일하다.\n",
    "\n",
    "이제 유일한 차이점은 가설함수 h이다.\n",
    "가설 함수)\n",
    "선형 회귀 : 일차 함수\n",
    "로지스틱 회귀 : 시그모이드 함수\n",
    "\n",
    "즉 아래 값의 h에 시그모이드 함수를 대입하여 각 theta 값을 업데이트 하면 된다.\n",
    "θj =θj −α / 1 m i=1∑m (hθ(x(i))−y(i)) * xj(i)\n",
    "\n",
    "손실함수 J를 편미분한 값에서 h에 시그모이드 함수를 대입하고,\n",
    "입력변수 m을 모두 대입하여 계산 후, 그 합계를 낸 다음,\n",
    "m으로 다시 나누어 평균을 낸 값에 알파값을 곱한 결괏값을 theta에서 빼서 업데이트.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "established-notion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35280508,  1.61640725, -1.83666046, -0.60286277])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"시그모이드 함수\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "def prediction(X, theta):\n",
    "    \"\"\"로지스틱 회귀 가정 함수\"\"\"\n",
    "    # 지난 과제에서 작성한 코드를 갖고 오세요\n",
    "    return sigmoid(X @ theta)  # 가설함수 h \n",
    "    \n",
    "\n",
    "def gradient_descent(X, theta, y, iterations, alpha):\n",
    "    \"\"\"로지스틱 회귀 경사 하강 알고리즘\"\"\"\n",
    "    m = len(X)  # 입력 변수 개수 저장\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # 코드를 쓰세요\n",
    "        error = prediction(X, theta) - y  # 가설함수에서 목표변수를 뺀 오차 값\n",
    "        theta -= alpha / m * X.T @ error  # 선형회귀 경사하강법과 동일\n",
    "            # X.T인 이유는 시그마를 사용하는 대신에 모든 입력 변수를 행렬로 나타냈기 때문\n",
    "        \n",
    "            \n",
    "    return theta\n",
    "    \n",
    "    \n",
    "# 입력 변수\n",
    "hours_studied = np.array([0.2, 0.3, 0.7, 1, 1.3, 1.8, 2, 2.1, 2.2, 3, 4, 4.2, 4, 4.7, 5.0, 5.9])  # 공부 시간 (단위: 100시간)\n",
    "gpa_rank = np.array([0.9, 0.95, 0.8, 0.82, 0.7, 0.6, 0.55, 0.67, 0.4, 0.3, 0.2, 0.2, 0.15, 0.18, 0.15, 0.05]) # 학년 내신 (백분률)\n",
    "number_of_tries = np.array([1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 2, 4, 1, 2])  # 시험 응시 횟수\n",
    "\n",
    "# 목표 변수\n",
    "passed = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])  # 시험 통과 여부 (0: 탈락, 1:통과)\n",
    "\n",
    "# 설계 행렬 X 정의\n",
    "X = np.array([\n",
    "    np.ones(16),  # 첫번째 theta는 상수 1로 만든다.\n",
    "    hours_studied,\n",
    "    gpa_rank,\n",
    "    number_of_tries\n",
    "]).T\n",
    "\n",
    "# 입력 변수 y 정의\n",
    "y = passed\n",
    "\n",
    "theta = [0, 0, 0, 0]  # 파라미터 초기값 설정\n",
    "theta = gradient_descent(X, theta, y, 300, 0.1)  # 경사 하강법을 사용해서 최적의 파라미터를 찾는다\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "framed-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn으로 로지스틱 회귀 머신러닝\n",
    "\n",
    "# 붓꽃(iris), 꽃받침(sepal), 꽃잎(petal)\n",
    "# target = 붓꽃의 종류. 붓꽃의 꽃받침, 꽃잎의 길이와 너비로 어떤 종인지 리턴\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pediatric-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "israeli-camel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "weird-irish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "X  # 4개의 속성. 입력변수 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "metropolitan-gospel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "145      2\n",
       "146      2\n",
       "147      2\n",
       "148      2\n",
       "149      2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(iris_data.target, columns=['class'])\n",
    "y  # 0, 1, 2 : 붓꽃의 종류. 즉 목표변수 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "loving-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "expired-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "y_train = y_train.values.ravel()  # y_ratin을 2차원 배열에서 1차원 배열로 바꿔준다.\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter=2000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = model.predict(X_test)\n",
    "y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "personalized-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
