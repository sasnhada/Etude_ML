{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "머신러닝에서 정규화는 손실 함수에 '정규화 항'을 더해서\n",
    "theta 값이 커지는 것을 방지하는 기법이다.\n",
    "\n",
    "theta값이 너무 클 경우 training data에 과적합이 되어,\n",
    "test data에 관한 손실함수 값이 증가한다.\n",
    "\n",
    "따라서 손실함수에 theta 값들의 절댓값을 더해줄 수 있다.\n",
    "\n",
    "\n",
    "# L1 정규화 (Lasso Regression Model) 래쏘 모델\n",
    "\n",
    "J(theta) = 1/2m (m)i=1∑(h(theta)(x(i))-y(i))^2 + (n)i=1∑|theta i|\n",
    "\n",
    "i 가 1부터 n의 값을 가지면서 시그마 안에 있는 항을 모두 더해준다.\n",
    "이 뒤 부분을 '정규화 항'이라고 한다.\n",
    "\n",
    "손실함수를 이렇게 정의하면 theta 값이 커질 수록 손실 함수도 커지고 \n",
    "theta 값이 작아질 수록 손실함수도 작아진다. \n",
    "즉 theta 값이 작을 수록 좋은 가설함수라는 의미이다.\n",
    "\n",
    "아래 두 개 항을 예시로 들어보았을 때,\n",
    "g(x) = 5 + 10x + 20x^2 + 5x^4 + 3x^5  ---> 정규화 항 5+2+3+3 - 20\n",
    "h(x) = 20 + 40x - 70x^2 + 50x^4 + 20x^5 ---> 정규화 항 40+70+50+20 = 180\n",
    "\n",
    "만약 g의 MSE가 5, h의 MSE가 1이라고 가정하였을 때,\n",
    "h의 평균제곱오차가 더 적어보이지만 정규화를 거치면,\n",
    "g(x) 손실 : 25\n",
    "h(x) 손실 : 181\n",
    "으로 h의 손실함수 값이 더 크다(오차가 크다)\n",
    "\n",
    "또한 정규화 항에는 람다λ 값을 곱해주는데,\n",
    "정규화항이 손실함수에 있어 얼마나 중요한지에 관한 상수값이다.\n",
    "즉 theta 값들이 커지는 것에 대해 얼마나 큰 패널티를 줄지를 정해준다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# L2 정규화 (Ridge Regression Model) 릿지 모델\n",
    "\n",
    "\n",
    "J(theta) = 1/2m (m)i=1∑(h(theta)(x(i))-y(i))^2 + (n)i=1∑theta(i)^2\n",
    "\n",
    "L2정규화의 식은 위와 같은데, 더해주는 정규화 항에서 theta 값을 제곱하는 것만 다르다.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imposed-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set에서 성능\n",
      "-----------------------\n",
      "오차: 4726.636439607449\n",
      "testing set에서 성능\n",
      "-----------------------\n",
      "오차: 4692.232442526967\n"
     ]
    }
   ],
   "source": [
    "# sclearn에서 Lasso 모델을 사용해보고 정규화가 실제로 과적합 문제를 해결해주는지 확인해보자.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 파일 경로 정의\n",
    "INSURANCE_FILE_PATH = 'insurance.csv'\n",
    "\n",
    "insurance_df = pd.read_csv(INSURANCE_FILE_PATH)  # 데이터를 pandas dataframe으로 갖고 온다 (insurance_df.head()를 사용해서 데이터를 한 번 살펴보세요!)\n",
    "insurance_df = pd.get_dummies(data=insurance_df, columns=['sex', 'smoker', 'region'])  # 필요한 열들에 One-hot Encoding을 해준다\n",
    "\n",
    "# 입력 변수 데이터를 따로 새로운 dataframe에 저장\n",
    "X = insurance_df.drop(['charges'], axis=1)\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(4)  # 4 차항 변형기를 정의\n",
    "polynomial_features = polynomial_transformer.fit_transform(X.values)  #  4차 항 변수로 변환\n",
    "\n",
    "features = polynomial_transformer.get_feature_names(X.columns)  # 새로운 변수 이름들 생성\n",
    "\n",
    "X = pd.DataFrame(polynomial_features, columns=features)  # 다항 입력 변수를 dataframe으로 만들어 준다\n",
    "y = insurance_df[['charges']]  # 목표 변수 정의\n",
    "\n",
    "# 여기 코드를 쓰세요\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "model = Lasso(alpha=1, max_iter=2000, normalize=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "# 체점용 코드\n",
    "mse = mean_squared_error(y_train, y_train_predict)\n",
    "\n",
    "print(\"training set에서 성능\")\n",
    "print(\"-----------------------\")\n",
    "print(f'오차: {sqrt(mse)}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "print(\"testing set에서 성능\")\n",
    "print(\"-----------------------\")\n",
    "print(f'오차: {sqrt(mse)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alert-lobby",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set에서 성능\n",
      "-----------------------\n",
      "오차: 4460.053305997337\n",
      "testing set에서 성능\n",
      "-----------------------\n",
      "오차: 4798.738543748564\n"
     ]
    }
   ],
   "source": [
    "# sclearn에서 Ridge 모델을 사용해보고 정규화가 실제로 과적합 문제를 해결해주는지 확인해보자\n",
    "# Lasso에서 바뀌는 부분은 리니어 모델의 Lasso가 Ridge로 바뀌는 부분과, alpha, max_iter 파라미터값이 바뀌는 것 뿐이다.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 파일 경로 정의\n",
    "INSURANCE_FILE_PATH = 'insurance.csv'\n",
    "\n",
    "insurance_df = pd.read_csv(INSURANCE_FILE_PATH)  # 데이터를 pandas dataframe으로 갖고 온다 (insurance_df.head()를 사용해서 데이터를 한 번 살펴보세요!)\n",
    "insurance_df = pd.get_dummies(data=insurance_df, columns=['sex', 'smoker', 'region'])  # 필요한 열들에 One-hot Encoding을 해준다\n",
    "\n",
    "# 입력 변수 데이터를 따로 새로운 dataframe에 저장\n",
    "X = insurance_df.drop(['charges'], axis=1)\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(4)  # 4 차항 변형기를 정의\n",
    "polynomial_features = polynomial_transformer.fit_transform(X.values)  #  4차 항 변수로 변환\n",
    "\n",
    "features = polynomial_transformer.get_feature_names(X.columns)  # 새로운 변수 이름들 생성\n",
    "\n",
    "X = pd.DataFrame(polynomial_features, columns=features)  # 다항 입력 변수를 dataframe으로 만들어 준다\n",
    "y = insurance_df[['charges']]  # 목표 변수 정의\n",
    "\n",
    "# 여기 코드를 쓰세요\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "model = Ridge(alpha=0.001, max_iter=2000, normalize=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "# 체점용 코드\n",
    "mse = mean_squared_error(y_train, y_train_predict)\n",
    "\n",
    "print(\"training set에서 성능\")\n",
    "print(\"-----------------------\")\n",
    "print(f'오차: {sqrt(mse)}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "print(\"testing set에서 성능\")\n",
    "print(\"-----------------------\")\n",
    "print(f'오차: {sqrt(mse)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "위에서 다항회귀 모델에만 L1, L2 정규화 기법을 적용하였으나,\n",
    "정규화는 모델의 파라미터(theta)의 대한 손실 함수를 최소화하는 모든 알고리즘에 적용할 수 있다.\n",
    "\n",
    "따라서 다중회귀, 다중다항회귀, 로지스틱회귀 모두에 정규화를 적용할 수 있다.\n",
    "해당 모델의 손실 함수에 정규화 항을 더해주면 된다.\n",
    "\n",
    "sclearn의 LogisticRegression 모델은 자동으로 L2 정규화를 사용한다.\n",
    "그러나 옵셔널 파라미터로 정규화 기법을 변경하거나 적용하지 않을 수가 있다.\n",
    "\n",
    "# model = LogisticRegression(penalty='none') ---> 정규화 미사용\n",
    "# model = LogisticRegression(panalty='l1') ---> ㅣ1\n",
    "# model = LogisticRegression(panalty='l2') ---> 기본값과 같음(L2)\n",
    "# model = LogisticRegression()  ---> 기본값 : 위와 같이 L2 정규화 사용\n",
    "\n",
    "\n",
    "딥러닝 모델도 손실 함수를 최소화 하는 알고리즘이다.\n",
    "딥러닝 모델도 과적합 되는 경우가 많기 때문에 정규화가 중요하다.\n",
    "\n",
    "딥러닝 모델의 파라미터는 theta가 아닌 ww로 주로 나타낸다.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
